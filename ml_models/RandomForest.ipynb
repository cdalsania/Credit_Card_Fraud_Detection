{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from config import CSV_FILE_URL\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a dataframe\n",
    "df = pd.read_csv(CSV_FILE_URL)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning¶\n",
    "Checking to see if there are any null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It could be seen that there are no null values in the dataset.\n",
    "\n",
    "Data Exploration\n",
    "Checking Data distribution w.r.t Target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df[['Class','Time']].groupby('Class').count()\n",
    "grouped_df = grouped_df.rename(columns={\"Time\":\"Count\"})\n",
    "grouped_df.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#It is evident from the above plot that data is highly imbalanced. The dataset has only ___ fraudulent transactions out of a total of ____,____ transactions, which is a mere ____%.\n",
    "\n",
    "Defining features\n",
    "Defining the predictor features and the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting predictor features. This will be used as x values.\n",
    "selected_features = df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]\n",
    "selected_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining predictor and target features to X and y respectively.\n",
    "# Note: Sklearn requires a two-dimensional array of values\n",
    "# so we use reshape to create this\n",
    "\n",
    "X = selected_features\n",
    "y = df[['Class']].values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Train Test Split¶\n",
    "Using Class for the y values (target feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn's `train_test_split` to split the data into training and testing datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape: \", X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Pre-processing\n",
    "Scale the data using the MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_minmax.transform(X_train)\n",
    "X_test_scaled = X_minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Model¶\n",
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomTreeModel = RandomTreeClassifier(n_estimators=200)\n",
    "randomTreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomTreeModel.fit(X_train_scaled, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {randomTreeModel.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {randomTreeModel.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the model\n",
    "randomTreePredictions = randomTreeModel.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomTreePredictProba = randomTreeModel.predict_proba(X_test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Classifier\")\n",
    "print(\"========================\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test.flatten(), randomTreePredictions)) \n",
    "print(\"Precision: \",precision_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"Recall: \",recall_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"F1-Score: \",f1_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"AUC score: \",roc_auc_score(y_test.flatten(), randomTreePredictions))\n",
    "print(classification_report(y_test.flatten(), randomTreePredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))\n",
    "p, r, t = precision_recall_curve(y_test.flatten(), randomTreePredictProba)\n",
    "plt.plot(p, r)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve - Random Forest Classifier')\n",
    "confusionMatrix = confusion_matrix(y_test.flatten(), randomTreePredictions) \n",
    "plt.figure(figsize =(6, 6)) \n",
    "sns.heatmap(confusionMatrix, xticklabels = ['Non Fraudulent', 'Fraudulent'],  \n",
    "            yticklabels = ['Non Fraudulent', 'Fraudulent'], annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix - Random Forest Classifier\") \n",
    "plt.ylabel('Actual Class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning¶\n",
    "Use GridSearchCV to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomTreeModel.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "randomTreeParamGrid = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "                         'criterion': ['gini','entropy'],\n",
    "                         'class_weight': [{0:1, 1:1, 2:2}, \"balanced\",\"balanced_subsample\", None],\n",
    "                         'max_features': ['auto','sqrt','log2',None],\n",
    "                        }\n",
    "randomTreeGrid = GridSearchCV(randomTreeModel, randomTreeParamGrid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch\n",
    "randomTreeGrid.fit(X_train_scaled, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(randomTreeGrid.best_params_)\n",
    "print(randomTreeGrid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hyperparameter tuned model\n",
    "randomTreeGridPredictions = randomTreeGrid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test.flatten(), randomTreeGridPredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertunedrandomTreeModel = randomTreeClassifier(criterion = 'gini', max_depth = 8, splitter = 'best')\n",
    "hypertunedrandomTreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertunedrandomTreeTreeModel.fit(X_train_scaled, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {hypertunedrandomTreeModel.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {hypertunedrandomTreeModel.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertunedrandomTreeModelPredictions = hypertunedrandomTreeModel.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypertunedrandomTreeModelPredictProba = hypertunedrandomTreeModel.predict_proba(X_test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "print(classification_report(y_test.flatten(), hypertunedrandomTreeModelPredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Classifier\")\n",
    "print(\"========================\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test.flatten(), randomTreePredictions)) \n",
    "print(\"Precision: \",precision_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"Recall: \",recall_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"F1-Score: \",f1_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"AUC score: \",roc_auc_score(y_test.flatten(), randomTreePredictions))\n",
    "print(classification_report(y_test.flatten(), randomTreePredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))\n",
    "p, r, t = precision_recall_curve(y_test.flatten(), randomTreePredictProba)\n",
    "plt.plot(p, r)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve - Random Forest Classifier')\n",
    "confusionMatrix = confusion_matrix(y_test.flatten(), randomTreePredictions) \n",
    "plt.figure(figsize =(6, 6)) \n",
    "sns.heatmap(confusionMatrix, xticklabels = ['Non Fraudulent', 'Fraudulent'],  \n",
    "            yticklabels = ['Non Fraudulent', 'Fraudulent'], annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix - Random Forest Classifier\") \n",
    "plt.ylabel('Actual Class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = selected_features.columns\n",
    "sorted(zip(hypertunedrandomTreeModel.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set top features. This will be used as x values.\n",
    "top_features = df[[ \n",
    "'V17',\n",
    "'V14',\n",
    "'V10',\n",
    "'V12',\n",
    "'V15',\n",
    "'V27',\n",
    "'V3',\n",
    "'V16',\n",
    "'V18',\n",
    "'V7',\n",
    "'V1',\n",
    "'V24',\n",
    "'V8',\n",
    "'V4',\n",
    "'V6',\n",
    "'V26',\n",
    "'V20',\n",
    "'V5',\n",
    "'V21',\n",
    "'V19',\n",
    "'V23',\n",
    "]]\n",
    "\n",
    "top_features.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split¶\n",
    "Use Class for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "# Note: Sklearn requires a two-dimensional array of values\n",
    "# so we use reshape to create this\n",
    "\n",
    "top_X = top_features\n",
    "top_y = df[['Class']].values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", top_X.shape, top_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_X_train, top_X_test, top_y_train, top_y_test = train_test_split(top_X, top_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_X_train.shape,top_X_test.shape,top_y_train.shape, top_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Scale the data using the MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_X_minmax = MinMaxScaler().fit(top_X_train)\n",
    "\n",
    "top_X_train_scaled = top_X_minmax.transform(top_X_train)\n",
    "top_X_test_scaled = top_X_minmax.transform(top_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model with Top features¶\n",
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_randomTreeModel = RandomTreeClassifier()\n",
    "top_randomTreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_randomTreeModel.fit(top_X_train_scaled, top_y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {top_randomTreeModel.score(top_X_train_scaled, top_y_train)}\")\n",
    "print(f\"Testing Data Score: {top_randomTreeModel.score(top_X_test_scaled, top_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "top_randomTreePredictions = top_randomTreeModel.predict(top_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_randomTreePredictProba = top_randomTreeModel.predict_proba(top_X_test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(top_y_test.flatten(), top_randomTreePredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))\n",
    "print(\"Accuracy:\", accuracy_score(top_y_test.flatten(), top_randomTreePredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Tree Classifier\")\n",
    "print(\"========================\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test.flatten(), hypertunedrandomTreeModelPredictions)) \n",
    "print(\"Precision: \",precision_score(y_test.flatten(), hypertunedrandomTreeModelPredictions))\n",
    "print(\"Recall: \",recall_score(y_test.flatten(), hypertunedrandomTreeModelPredictions))\n",
    "print(\"F1-Score: \",f1_score(y_test.flatten(), hypertunedrandomTreeModelPredictions))\n",
    "print(\"AUC score: \",roc_auc_score(y_test.flatten(), hypertunedrandomTreeModelPredictions))\n",
    "print(classification_report(y_test.flatten(), hypertunedrandomTreeModelPredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))\n",
    "\n",
    "p, r, t = precision_recall_curve(y_test.flatten(), hypertunedrandomTreeModelPredictProba)\n",
    "plt.plot(p, r)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve - Decision Tree Classifier')\n",
    "\n",
    "confusionMatrix = confusion_matrix(y_test.flatten(), hypertunedrandomTreeModelPredictions) \n",
    "plt.figure(figsize =(6, 6)) \n",
    "sns.heatmap(confusionMatrix, xticklabels = ['Non Fraudulent', 'Fraudulent'],  \n",
    "            yticklabels = ['Non Fraudulent', 'Fraudulent'], annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix - Decision Tree Classifier\") \n",
    "plt.ylabel('Actual Class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "Use GridSearchCV to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_decisionTreeModel.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "top_randomTreeParamGrid = {'criterion':['gini', 'entropy'],\n",
    "                             'splitter': ['best','random'],\n",
    "                             'max_depth': [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "top_randomTreeGrid = GridSearchCV(top_randomTreeModel, top_randomTreeParamGrid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch\n",
    "top_randomTreeGrid.fit(top_X_train_scaled, top_y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_randomTreeGrid.best_params_)\n",
    "print(top_randomTreeGrid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hyperparameter tuned model\n",
    "top_randomTreeGridPredictions = top_randomTreeGrid.predict(top_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(top_y_test.flatten(), top_randomTreeGridPredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hypertunedrandomTreeModel = randomTreeClassifier(criterion = 'entropy', max_depth = 7, splitter = 'random')\n",
    "top_hypertunedrandomTreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hypertunedrandomTreeModel.fit(top_X_train_scaled, top_y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {top_hypertunedrandomTreeModel.score(top_X_train_scaled, top_y_train)}\")\n",
    "print(f\"Testing Data Score: {top_hypertunedrandomTreeModel.score(top_X_test_scaled, top_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hypertunedrandomTreeModelPredictions = top_hypertunedrandomTreeModel.predict(top_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hypertunedrandomTreeModelPredictProba = top_hypertunedrandomTreeModel.predict_proba(top_X_test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(top_y_test.flatten(), top_hypertunedrandomTreeModelPredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Classifier\")\n",
    "print(\"========================\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test.flatten(), randomTreePredictions)) \n",
    "print(\"Precision: \",precision_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"Recall: \",recall_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"F1-Score: \",f1_score(y_test.flatten(), randomTreePredictions))\n",
    "print(\"AUC score: \",roc_auc_score(y_test.flatten(), randomTreePredictions))\n",
    "print(classification_report(y_test.flatten(), randomTreePredictions,\n",
    "                            target_names=[\"Non Fraudulent\", \"Fraudulent\"]))\n",
    "p, r, t = precision_recall_curve(y_test.flatten(), randomTreePredictProba)\n",
    "plt.plot(p, r)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve - Random Forest Classifier')\n",
    "confusionMatrix = confusion_matrix(y_test.flatten(), randomTreePredictions) \n",
    "plt.figure(figsize =(6, 6)) \n",
    "sns.heatmap(confusionMatrix, xticklabels = ['Non Fraudulent', 'Fraudulent'],  \n",
    "            yticklabels = ['Non Fraudulent', 'Fraudulent'], annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix - Random Forest Classifier\") \n",
    "plt.ylabel('Actual Class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'RandomTreeClassifierModel.sav'\n",
    "joblib.dump(hypertunedRandomTreeModel, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
